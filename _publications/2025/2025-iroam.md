---
title:          "IROAM: Improving Roadside Monocular 3D Object Detection Learning from Autonomous Vehicle Data Domain"
date:           2025-01-01 00:01:00 +0800
selected:       false
pub:            "IEEE International Conference on Robotics and Automation (ICRA)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "2025"
abstract: >-
  In autonomous driving, the perception capabilities of the ego-vehicle can be enhanced through roadside sensors, which provide a holistic view of the environment. However, existing monocular detection methods designed for vehicle cameras are not suitable for roadside cameras due to significant viewpoint domain gaps. To bridge this gap and improve roadside monocular 3D object detection, we propose IROAM, a semantic-geometry decoupled contrastive learning framework that simultaneously takes both vehicle-side and roadside data as input. IROAM comprises two key modules. The In-Domain Query Interaction module leverages a transformer to learn content and depth information for each domain and outputs object queries. The Cross-Domain Query Enhancement module, aiming to learn better feature representations from both domains, decouples queries into semantic and geometric parts. Only the semantic part is used for contrastive learning. Experiments demonstrate that IROAM significantly improves the performance of roadside detectors. The results validate IROAM's capability to effectively learn and integrate cross-domain information.
cover:          /assets/images/covers_researches/IROAM.png
authors:
  - Zhe Wang*
  - Xiaoliang Huo*
  - Siqi Fan
  - Jingjing Liu
  - Ya-Qin Zhang
  - Yan Wang
links:
  Paper: https://arxiv.org/pdf/2501.18162
  第三方中文解读: https://mp.weixin.qq.com/s/4GyP8exGaNEYJABYJuiySg
---
