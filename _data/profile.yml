primary_name: "Siqi Fan"
secondary_name: ""
navbar_name: "Siqi Fan"

positions:
- logo: /assets/images/badges/THU.png  # Logo is optional
  name: Researcher @ AIR, Tsinghua University

email: "leofansq@gmail.com"
# cv_link: /assets/files/resume.pdf
gscholar: Ahy5smMAAAAJ  # This is an example, replace it with your own Google Scholar ID
github: leofansq
# twitter: your_twitter_id  # Do not include the '@' symbol
# wechat_qrcode: /assets/images/etc/wechat.jpg
# wechat_prompt: >-
#   Please tell me your <strong>name</strong> and <strong>affiliation</strong> (current or past) when adding my wechat. Thanks!
# linkedin: your-linked-in-id
# orcid: 0000-0000-0000-0000

short_bio_text_justify: true
short_bio: >-
  <p>
  I'm Siqi Fan (范嗣祺), a researcher at Institute for AI Industry Research, Tsinghua University <em>(AIR, THU)</em>. Previously, I obtained my M.S. degree from the Institute of Automation, Chinese Academy of Sciences <em>(CASIA)</em> in 2022 and my B.E. degree from Shanghai Jiao Tong University <em>(SJTU)</em> in 2019.
  </p>
  <p>
  My research interests lie broadly in Representation Learning in Complex Systems, spanning from the macro <em>physical world</em> to the micro <em>biological world</em>. With the goal of increasing human "Available Time" through AI technology, I primarily concentrate on 
  <ul>
    <li>Autonomous Driving (physical) for improving traffic efficiency and safety;</li> 
    <li>Biomedical Discovery (biological) for extending lifespan.</li>
  </ul>
  Fueled by a passion for innovation, I am dedicated to pushing the frontiers of technology and developing impactful products.
  </p>
  <p>
  I love music and visual arts.
  </p>

portrait_url: /assets/images/portrait.jpg
# portrait_caption: >-
#   Photo by Manja Vitolic on Unsplash (this caption is optional, comment it out to disable).

education:
- name: Shanghai Jiao Tong University (SJTU)
  logo: /assets/images/badges/SJTU.png
  position: >- 
    School of Electronic Information and Electrical Engineering <br/>
    B.E. in Automation
  date: Sep. 2015 - Jul. 2019
- name: University of Chinese Academy of Sciences (UCAS)
  logo: /assets/images/badges/UCAS.png
  position: >- 
    Institute of Automation <br/>
    M.S. in Automation
  date: Sep. 2019 - Jul. 2022

experience:
- name: Autonomous System Group, Intel Labs China (ILC)
  logo: /assets/images/badges/INTEL.png
  position: Research Intern
  date: Aug. 2020 - Dec. 2021
- name: Institute of Automation, Chinese Academy of Sciences (CASIA)
  logo: /assets/images/badges/CASIA.png
  position: Student Researcher
  date: Sep. 2019 - Jul. 2022
- name: Institute for AI Industry Research, Tsinghua University (AIR, THU)
  logo: /assets/images/badges/THU.png
  position: Researcher
  date: Jul. 2022 - Present

service:
- title: Program Committee & Area Chair
  content: >-
    <p>
    <a href="https://coop-intelligence.github.io/" target="_blank">Workshop on Multi-Agent Embodied Intelligent Systems Meet Generative-AI Era</a> @ <em>CVPR'25</em><br>
    <a href="https://coop-intelligence.github.io/eccv2024/" target="_blank">Workshop on Cooperative Intelligence for Embodied AI</a> @ <em>ECCV'24</em>
    </p>
- title: Journal Reviewer
  content: >-
    <p>
    IEEE (TIP, TCSVT, TVT, TIV, TITS, TMC, JIoT, ITSM), IJCV, IET (CV, CSR), PR, Trans. PartC, Neurocomputing
    </p>
- title: Conference Reviewer
  content: >-
    <p>
    NeurIPS, CVPR, ICCV, ECCV, AAAI, ICRA, IROS, WACV, ITSC
    </p>
- title: Invited Speaker
  content: >-
    <p>
    <a href="https://drive.google.com/file/d/1dyss0rBnvK7iMQOcFYcmq2j5nD3MRVD8/view?usp=drive_link" target="_blank">Traffic scenes understanding and simulation testing</a> @ <em>ITSC'22</em>
    </p>

awards:
- name: National Scholarship
  date: 2021
- name: Pan Deng First-class Scholarship, CAS 
  date: 2022
- name: Excellent Scholarship, SJTU
  date: 2018
- name: China Industrial Intelligence Challenge, State-level Outstanding Award, CAA
  date: 2018


research:
- name: Autonomous Driving (AD)
  subarea:
  - name: Onboard System (Intelligent Vehicle)
    content: >-
      <p>
      My exploration of vehicle-side environment perception began with drivable area detection <em>(ITSC’20)</em>. Since then, I have proposed a series of perception algorithms, including an RGB 2D object detection approach designed for complex traffic environments <em>(FII-CenterNet, T-VT’21)</em>, a semi-supervised learning approach for RGB 2D segmentation <em>(CPCL, T-IP’22)</em>, an RGB-T segmentation approach tailored for challenging lighting conditions <em>(SpiderMesh, TechReport’23)</em>, and a 3D segmentation approach for large-scale point clouds <em>(SCF-Net, CVPR’21)</em>.
      </p>
  - name: Roadside System (Intelligent Infrastructure)
    content: >-
      <p>
      Compared to the well-studied vehicle-side perception, roadside perception faces several unique challenges, and the calibration noise caused by inevitable natural factors is one of them. Addressing that, a calibration-free BEV representation network is proposed to alleviate inaccurate calibration parameter problem <em>(CBR, IROS’23)</em>. The development of roaside perception has been hindered by a lack of available data. On the one hand, a semantic-geometry decoupled contrastive learning framework is introduced to enhance roadside perception performance by leveraging vehicle-side data <em>(IROAM, ICRA’25)</em>; On the other hand, the first large-scale real-world dataset for roadside cooperative perception is released, complete with benchmarks, to stimulate research in practical I2I perception <em>(RCooper, CVPR’24)</em>.
      </p>
  - name: Cooperative Autonomous Driving System (V2X)
    content: >-
      <p>
      Cooperative perception can significantly enhance individual perception performance by providing additional viewpoints and expanding the sensing field. A scene-level feature cooperative perception approach is proposed <em>(EMIFF, ICRA’24)</em>. To enable interpretable, instance-level, and flexible feature interactions, the concept of query cooperation is introduced, along with a cooperative perception framework that allows query streams to flow among agents <em>(QUEST, ICRA’24)</em>. Additionally, motion forecasting can also benefit from learning cooperative trajectory representations <em>(NeurIPS’24)</em>. Beyond focusing on improving individual modules, a pioneering end-to-end cooperative autonomous driving framework is introduced <em>(UniV2X, AAAI’25)</em>, and several workshops/challenges are organized <em>(ECCV’24 & CVPR’25)</em>.
      </p>
- name: Biomedical Discovery (BD)
  subarea:
  - name: Biomedical Agent System
    content: >-
      <p>
      The microscopic biological system is intriguing but challenging. An all-atom framework is explored to enable consistent representation and interaction modeling across different biomolecules <em>(PharMolixFM, TechReport’25)</em>.
      </p>
  - name: Human-Agent Interaction System
    content: >-
      <p>
      Recent advances in LLMs have illuminated the path toward developing knowledgeable and versatile AI research assistants across various scientific domains. Multimodal large language models are particularly promising, as they bridge the semantic gap between natural language and other modalities such as molecules, proteins, and visual information. In this context, a multimodal large language model is proposed to assist biomedical research <em>(BioMedGPT, J-BHI’24)</em>, and it is further extented to the first biomedical multimodal reasoning model, BioMedGPT-R1, through reinforcement learning <em>(BioMedGPT-R1, TechReport’25)</em>. Molecules are often depicted as 2D images in scientific papers and patents. To extract and analyze molecular information from such documents, the task of Optical Chemical Structure Understanding (OCSU) has been introduced and systematically explored <em>(OCSU, TechReport’25)</em>. To further facilitate molecule-centric scientific discovery, we propose BioMedGPT-Mol, a unified model designed to support both molecular understanding and molecular generation tasks <em>(BioMedGPT-Mol, TechReport’25)</em>.
      </p>
  - name: Multi-Agent Cooperation System
    content: >-
      <p>
      Multi-agent cooperation holds great potential for solving complex scientific research tasks in an autonomous manner. To facilitate further exploration in this area, an agent platform specifically designed for biomedicine and life science is presented and open-sourced <em>(<a href="https://github.com/PharMolix/OpenBioMed" target="_blank">OpenBioMed</a>)</em>.
      </p>
